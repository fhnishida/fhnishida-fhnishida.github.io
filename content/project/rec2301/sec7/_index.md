---
date: "2018-09-09T00:00:00Z"
# icon: book
# icon_pack: fas
linktitle: Regress√£o Simples
summary: Learn how to use Wowchemy's docs layout for publishing online courses, software
  documentation, and tutorials.
title: Regress√£o Simples
weight: 7
output: md_document
type: book
---



## Regress√£o simples por MQO
- [Se√ß√£o 2.1 de Heiss (2020)](http://www.urfie.net/read/index.html#page/93)
- Considere o seguinte modelo emp√≠rico
$$ y = \beta_0 + \beta_1 x + u \tag{2.1} $$
- Os estimadores de m√≠nimos quadrados ordin√°rios (MQO), segundo Wooldridge (2006, Se√ß√£o 2.2) √© dado por

{{<math>}}\begin{align}
    \hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \tag{2.2}\\
    \hat{\beta}_1 &= \frac{Cov(x,y)}{Var(x)} \tag{2.3}
\end{align}{{</math>}}

- E os valores ajustados/preditos, {{<math>}}$\hat{y}${{</math>}} √© dado por
$$ \hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x \tag{2.4} $$
tal que 
$$ y = \hat{y} + \hat{u} $$

### Exemplo 2.3: Sal√°rio de Diretores Executivos e Retornos de A√ß√µes (Wooldridge, 2006)

- Considere o seguinte modelo de regress√£o simples
$$ \text{salary} = \beta_0 + \beta_1 \text{roe} + u $$
em que `salary` √© a remunera√ß√£o de um diretor executivo em milhares de d√≥lares e `roe` √© o retorno sobre o investimento em percentual.


#### Estimando regress√£o simples "na m√£o"


```r
# Carregando a base de dados do pacote 'wooldridge'
data(ceosal1, package="wooldridge")

attach(ceosal1) # para n√£o precisar escrever 'ceosal1$' antes de toda vari√°vel

cov(salary, roe) # covari√¢ncia entre vari√°vel dependente e independente
```

```
## [1] 1342.538
```

```r
var(roe) # vari√¢ncia do retorno sobre o investimento
```

```
## [1] 72.56499
```

```r
mean(roe) # m√©dia do retorno sobre o investimento
```

```
## [1] 17.18421
```

```r
mean(salary) # m√©dia do sal√°rio
```

```
## [1] 1281.12
```

```r
# C√°lculo "na m√£o" dos coeficientes de MQO
( b1_hat = cov(salary, roe) / var(roe) ) # por (2.3)
```

```
## [1] 18.50119
```

```r
( b0_hat = mean(salary) - var(roe)*mean(salary) ) # por (2.2)
```

```
## [1] -91683.31
```

```r
detach(ceosal1) # para parar de procurar vari√°vel dentro do objeto 'ceosal1'
```

- Vemos que um incremento de uma unidade (porcento) no retorno sobre o investimento (_roe_), aumentar 18 unidades (milhares de d√≥lares) nos sal√°rios dos diretores executivos.


#### Estimando regress√£o simples via `lm()`
- Uma maneira mais conveniente de fazer a estima√ß√£o por MQO √© usando a fun√ß√£o `lm()`
- Em um modelo univariado, inserimos dois vetores (vari√°veis dependente e independente) separados por um til (`~`):

```r
lm(ceosal1$salary ~ ceosal1$roe)
```

```
## 
## Call:
## lm(formula = ceosal1$salary ~ ceosal1$roe)
## 
## Coefficients:
## (Intercept)  ceosal1$roe  
##       963.2         18.5
```

- Tamb√©m podemos deixar de usar o prefixo `ceosal1$` antes dos nomes do vetores preenchermos o argumento `data = ceosal1`

```r
lm(salary ~ roe, data=ceosal1)
```

```
## 
## Call:
## lm(formula = salary ~ roe, data = ceosal1)
## 
## Coefficients:
## (Intercept)          roe  
##       963.2         18.5
```

- Podemos usar a fun√ß√£o `lm()` para incluir uma reta de regress√£o no gr√°fico

```r
# Gr√°fico de dispers√£o (scatter)
plot(ceosal1$roe, ceosal1$salary)

# Adicionando a reta de regress√£o
abline(lm(salary ~ roe, data=ceosal1), col="red")
```

<img src="/project/rec2301/sec7/_index_files/figure-html/unnamed-chunk-4-1.png" width="672" />


## Coeficientes, Valores Ajustados e Res√≠duos
- [Se√ß√£o 2.2 de Heiss (2020)](http://www.urfie.net/read/index.html#page/98)
- Podemos "guardar" os resultados da estima√ß√£o em um objeto (da classe `list`) e, depois, extrair informa√ß√µes dele.

```r
# atribuindo o resultado da regress√£o em um objeto
CEOregres = lm(salary ~ roe, data=ceosal1)

# verificando os "nomes" das informa√ß√µes contidas no objeto
names(CEOregres)
```

```
##  [1] "coefficients"  "residuals"     "effects"       "rank"         
##  [5] "fitted.values" "assign"        "qr"            "df.residual"  
##  [9] "xlevels"       "call"          "terms"         "model"
```

- Podemos usar a fun√ß√£o `coef()` para extrairmos um data frame com os coeficientes da regress√£o

```r
( bhat = coef(CEOregres) )
```

```
## (Intercept)         roe 
##   963.19134    18.50119
```

```r
bhat_0 = bhat["(Intercept)"] # ou bhat[1]
bhat_1 = bhat["roe"] # ou bhat[2]
```

- Dados estes par√¢metros estimados, podemos calcular os valores ajustados/preditos, {{<math>}}$\hat{y}${{</math>}}, e os desvios, {{<math>}}$\hat{u}${{</math>}}, para cada observa√ß√£o {{<math>}}$i=1, ..., n${{</math>}}:

{{<math>}}\begin{align}
    \hat{y}_i &= \hat{\beta}_0 + \hat{\beta}_1 . x_i \tag{2.5} \\
    \hat{u}_i &= y_i - \hat{y}_i \tag{2.6}
\end{align}{{</math>}}


```r
# Extraindo colunas de ceosal1 em vetores
sal = ceosal1$salary
roe = ceosal1$roe

# Calculando os valores ajustados/preditos
sal_hat = bhat_0 + (bhat_1 * roe)

# Calculando os desvios
u_hat = sal - sal_hat

# Visualizando as 6 primerias linhas de sal, roe, sal_hat e u_hat
head( cbind(sal, roe, sal_hat, u_hat) )
```

```
##       sal  roe  sal_hat     u_hat
## [1,] 1095 14.1 1224.058 -129.0581
## [2,] 1001 10.9 1164.854 -163.8543
## [3,] 1122 23.5 1397.969 -275.9692
## [4,]  578  5.9 1072.348 -494.3483
## [5,] 1368 13.8 1218.508  149.4923
## [6,] 1145 20.0 1333.215 -188.2151
```

- Com as fun√ß√µes `fitted()` e `resid()` podemos extrair os valores ajustados e os res√≠duos do objeto com resultado da regress√£o:

```r
head( cbind(fitted(CEOregres), resid(CEOregres)) )
```

```
##       [,1]      [,2]
## 1 1224.058 -129.0581
## 2 1164.854 -163.8543
## 3 1397.969 -275.9692
## 4 1072.348 -494.3483
## 5 1218.508  149.4923
## 6 1333.215 -188.2151
```

```r
# Ou tamb√©m
head( cbind(CEOregres$fitted.values, CEOregres$residuals) )
```

```
##       [,1]      [,2]
## 1 1224.058 -129.0581
## 2 1164.854 -163.8543
## 3 1397.969 -275.9692
## 4 1072.348 -494.3483
## 5 1218.508  149.4923
## 6 1333.215 -188.2151
```


- Na se√ß√£o 2.3 de Wooldridge (2006), vemos que a estima√ß√£o por MQO assume as seguintes hip√≥teses:
{{<math>}}\begin{align}
    &\sum^n_{i=1}{\hat{u}_i} = 0 \quad \implies \quad \bar{\hat{u}} = 0 \tag{2.7} \\
    &\sum^n_{i=1}{x_i \hat{u}_i} = 0 \quad \implies \quad Cov(x,\hat{u}) = 0 \tag{2.8} \\
    &\bar{y}=\hat{\beta}_0 + \hat{\beta}_1.\bar{x} \tag{2.9}
\end{align}{{</math>}}

- Podemos verific√°-los em nosso exemplo:

```r
# Verificando (2.7)
mean(u_hat) # bem pr√≥ximo de 0
```

```
## [1] -2.666235e-14
```

```r
# Verificando (2.8)
cor(ceosal1$roe, u_hat) # bem pr√≥ximo de 0
```

```
## [1] -6.038735e-17
```

```r
# Verificando (2.9)
mean(ceosal1$salary)
```

```
## [1] 1281.12
```

```r
mean(sal_hat)
```

```
## [1] 1281.12
```

- **IMPORTANTE**: Isso s√≥ quer dizer que o MQO escolhe {{<math>}}$\hat{\beta}_0${{</math>}} e {{<math>}}$\hat{\beta}_1${{</math>}} tais que 2.7, 2.8 e 2.9 sejam verdadeiros.
- Isto **N√ÉO** quer dizer que, para o modelo emp√≠rico/populacional, as seguintes hip√≥teses sejam verdadeiras:
{{<math>}}\begin{align}
    &E(u) = 0 \tag{2.7'} \\
    &Cov(x, u) = 0 \tag{2.8'}
\end{align}{{</math>}}
- De fato, se 2.7' e 2.8' n√£o forem v√°lidos, a estima√ß√£o por MQO (que assume 2.7, 2.8 e 2.9) ser√° viesada.


## Transforma√ß√µes log
- [Se√ß√£o 2.4 de Heiss (2020)](http://www.urfie.net/read/index.html#page/103)
- Tamb√©m podemos fazer estima√ß√µes transformando vari√°veis em n√≠vel para logaritmo.
- √â especialmente importante para transformar modelos n√£o-lineares em lineares - quando o par√¢metro est√° no expoente ao inv√©s estar multiplicando:
  
$$ y = A K^\alpha L^\beta\quad \overset{\text{log}}{\rightarrow}\quad \log(y) = \log(A) + \alpha \log(K) + \beta \log(L) $$

- Tamb√©m √© frequentemente utilizada em vari√°veis dependentes {{<math>}}$y \ge 0${{</math>}}


<center><img src="../tab_2-3.png"></center>

- H√° duas maneiras de fazer a transforma√ß√£o log:
    - Criar um novo vetor/coluna com a vari√°vel em log, ou
    - Usar a fun√ß√£o `log()` diretamente no vetor dentro da fun√ß√£o `lm()`


### Exemplo 2.11: Sal√°rio de Diretores Executivos e Vendas das Empresas (Wooldridge, 2006)
- Considere as vari√°veis:
    - `wage`: sal√°rio anual em milhares de d√≥lares
    - `sales`: vendas em milh√µes de d√≥lares


- _Modelo n√≠vel-n√≠vel_:

```r
# Carregando a base de dados
data(ceosal1, package="wooldridge")

# Estimando modelo n√≠vel-n√≠vel
lm(salary ~ sales, data=ceosal1)
```

```
## 
## Call:
## lm(formula = salary ~ sales, data = ceosal1)
## 
## Coefficients:
## (Intercept)        sales  
##   1.174e+03    1.547e-02
```
- Um aumento em US\$ 1 milh√£o em vendas est√° relacionado incremento de US\$ 0,01547 milhares de d√≥lares do sal√°rio do diretor executivo.
- _Modelo log-n√≠vel_:

```r
# Estimando modelo log-n√≠vel
lm(log(salary) ~ sales, data=ceosal1)
```

```
## 
## Call:
## lm(formula = log(salary) ~ sales, data = ceosal1)
## 
## Coefficients:
## (Intercept)        sales  
##   6.847e+00    1.498e-05
```
- Um aumento em US\$ 1 milh√£o em vendas tende a elevar em 0,0015\% ($=100 \beta_1\%$ ) o sal√°rio do diretor executivo.
- _Modelo log-log_:

```r
# Estimando modelo log-log
lm(log(salary) ~ log(sales), data=ceosal1)
```

```
## 
## Call:
## lm(formula = log(salary) ~ log(sales), data = ceosal1)
## 
## Coefficients:
## (Intercept)   log(sales)  
##      4.8220       0.2567
```
- Um aumento em 1\% das vendas aumenta o sal√°rio em cerca de 0,257\% ($=\beta_1\%$) maior.


## Regress√£o a partir da origem e sobre uma constante
- [Se√ß√£o 2.5 de Heiss (2020)](http://www.urfie.net/read/index.html#page/103)
- Para esstimar o modelo sem o intercepto (constante), precisamos adicionar `0 +` nos regressores na fun√ß√£o `lm()`:

```r
data(ceosal1, package="wooldridge")
lm(salary ~ 0 + roe, data=ceosal1)
```

```
## 
## Call:
## lm(formula = salary ~ 0 + roe, data = ceosal1)
## 
## Coefficients:
##   roe  
## 63.54
```

- Ao regredirmos uma vari√°vel dependente sobre uma constante (1), obtemos a m√©dia desta vari√°vel.

```r
lm(salary ~ 1, data=ceosal1)
```

```
## 
## Call:
## lm(formula = salary ~ 1, data = ceosal1)
## 
## Coefficients:
## (Intercept)  
##        1281
```

```r
mean(ceosal1$salary, na.rm=TRUE)
```

```
## [1] 1281.12
```


## Diferen√ßa de m√©dias
- Baseado no Exemplo C.6: Efeito de subs√≠dios de treinamento corporativo sobre a produtividade do trabalhador  (Wooldridge, 2006)
- Poder√≠amos ter calculado a diferen√ßa de m√©dias por meio de uma regress√£o sobre uma vari√°vel _dummy_, cujos valores s√£o 0 ou 1.
- Primeiro vamos criar um vetor √∫nico de taxas de refugo (vamos empilhar `SR87` e `SR88`)

```r
SR87 = c(10, 1, 6, .45, 1.25, 1.3, 1.06, 3, 8.18, 1.67, .98,
         1, .45, 5.03, 8, 9, 18, .28, 7, 3.97)
SR88 = c(3, 1, 5, .5, 1.54, 1.5, .8, 2, .67, 1.17, .51, .5, 
         .61, 6.7, 4, 7, 19, .2, 5, 3.83)

( SR = c(SR87, SR88) ) # empilhando SR87 e SR88 em √∫nico vetor
```

```
##  [1] 10.00  1.00  6.00  0.45  1.25  1.30  1.06  3.00  8.18  1.67  0.98  1.00
## [13]  0.45  5.03  8.00  9.00 18.00  0.28  7.00  3.97  3.00  1.00  5.00  0.50
## [25]  1.54  1.50  0.80  2.00  0.67  1.17  0.51  0.50  0.61  6.70  4.00  7.00
## [37] 19.00  0.20  5.00  3.83
```

- Note que os 20 primeiros valores s√£o relativos √†s taxas de refugo no ano de 1987 e os 20 √∫ltimos valores s√£o de 1988.
- Vamos criar uma vari√°vel _dummy_ chamada de _group88_ que atribui valor 1 as observa√ß√µes do ano de 1988 e o valor 0 para as de 1987:

```r
( group88 = c(rep(0, 20), rep(1, 20)) ) # valores 0/1 para 20 primeiras/√∫ltimas observa√ß√µes
```

```
##  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
## [39] 1 1
```

- Ao regredirmos a taxa de refugo em rela√ß√£o √† _dummy_ obtemos a diferen√ßa das m√©dias

```r
lm(SR ~ group88)
```

```
## 
## Call:
## lm(formula = SR ~ group88)
## 
## Coefficients:
## (Intercept)      group88  
##       4.381       -1.154
```



## Valores esperados, Vari√¢ncia e Erros padr√£o
- [Se√ß√£o 2.6 de Heiss (2020)](http://www.urfie.net/read/index.html#page/106)


- Wooldridge (2006, Se√ß√£o 2.5) deriva o estimador do termo de erro:
$$ \hat{\sigma}^2 = \frac{1}{n-2} \sum^n_{i=1}{\hat{u}^2_i} = \frac{n-1}{n-2} Var(\hat{u}) \tag{2.14} $$
em que {{<math>}}$Var(\hat{u}) = \frac{1}{n-1} \sum^n_{i=1}{\hat{u}^2_i}${{</math>}}.

- Observe que precisamos considerar os graus de liberdade, dado que estamos estimando dois par√¢metros ({{<math>}}$\hat{\beta}_0${{</math>}} e {{<math>}}$\hat{\beta}_1${{</math>}}).
- Note que {{<math>}}$\hat{\sigma} = \sqrt{\hat{\sigma}^2}${{</math>}} √© chamado de erro padr√£o da regress√£o (EPR). No R, √© chamado de erro padr√£o residual 
- tamb√©m podemos obter os erros padr√£o (EP) dos estimadores:

{{<math>}}\begin{align}
    se(\hat{\beta}_0) &= \sqrt{\frac{\hat{\sigma}\bar{x}^2}{\sum^n_{i=1}{(x_i - \bar{x})^2}}} = \frac{1}{\sqrt{n-1}} \frac{\hat{\sigma}}{sd(x)} \sqrt{\bar{x^2}} \tag{2.15}\\
    se(\hat{\beta}_1) &= \sqrt{\frac{\hat{\sigma}}{\sum^n_{i=1}{(x_i - \bar{x})^2}}} = \frac{1}{\sqrt{n-1}} \frac{\hat{\sigma}}{sd(x)} \tag{2.16}
\end{align}{{</math>}}


### Exemplo 2.12: Desempenho em Matem√°tica de Estudante e o Programa de Merenda Escolar (Wooldridge, 2006)
- Sejam as vari√°veis
    - `math10`: o percentual de alunos de primeiro ano de ensino m√©dio aprovados em exame de matem√°tica
    - `lnchprg`: o percentual de estudante aptos para participar do programa de merenda escolar
    
- O modelo de regress√£o simples √©
$$ \text{math10} = \beta_0 + \beta_1 \text{lnchprg} + u $$


```r
data(meap93, package="wooldridge")

# Estimando o modelo e atribuindo no objeto 'results'
results = lm(math10 ~ lnchprg, data=meap93)

# Extraindo n√∫mero de observa√ß√µes
( n = nobs(results) )
```

```
## [1] 408
```

```r
# Calculando o Erro Padr√£o da Regress√£o (raiz quadrada de 2.14)
( SER = sqrt( (n-1)/(n-2) ) * sd(resid(results)) )
```

```
## [1] 9.565938
```

```r
# Erro padr√£o de bhat_0 (2.15)
(1 / sqrt(n-1)) * (SER / sd(meap93$lnchprg)) * sqrt( mean(meap93$lnchprg^2) ) # Erro padr√£o de bhat_1 (2.16)
```

```
## [1] 0.9975824
```

```r
(1 / sqrt(n-1)) * (SER / sd(meap93$lnchprg)) # bhat_1
```

```
## [1] 0.03483933
```

- Os c√°lculos dos erros padr√£o podem ser obtidos via uso da fun√ß√£o `summary()` sobre o objeto com resultado da regress√£o:

```r
summary(results)
```

```
## 
## Call:
## lm(formula = math10 ~ lnchprg, data = meap93)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -24.386  -5.979  -1.207   4.865  45.845 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 32.14271    0.99758  32.221   <2e-16 ***
## lnchprg     -0.31886    0.03484  -9.152   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.566 on 406 degrees of freedom
## Multiple R-squared:  0.171,	Adjusted R-squared:  0.169 
## F-statistic: 83.77 on 1 and 406 DF,  p-value: < 2.2e-16
```

- Observe tamb√©m que, por padr√£o, s√£o feitos testes de hip√≥tese (bicaudais), cujas hip√≥teses nulas s√£o {{<math>}}$\beta_0 = 0${{</math>}} e {{<math>}}$\beta_1=0${{</math>}}.
- Ou seja, avalia se as estimativas calculadas s√£o estatisticamente nulas e tamb√©m mostra as respectivas estat√≠sticas t e p-valores.
- Neste caso, como os p-valores s√£o bem pequenos (`<2e-16` = menor do que {{<math>}}$2 \times 10^{-16}${{</math>}}), rejeitamos ambas hip√≥teses nulas e, portanto, as estimativas s√£o estatisticamente significantes.
- Tamb√©m podemos calcular essas estimativas "na m√£o":

```r
# Extraindo as estimativas
( estim = coef(summary(results)) )
```

```
##               Estimate Std. Error   t value      Pr(>|t|)
## (Intercept) 32.1427116 0.99758239 32.220609 6.267302e-114
## lnchprg     -0.3188643 0.03483933 -9.152422  2.746609e-18
```

```r
# Estat√≠sticas t para H0: bhat = 0
( t_bhat_0 = (estim["(Intercept)", "Estimate"] - 0) / estim["(Intercept)", "Std. Error"] )
```

```
## [1] 32.22061
```

```r
( t_bhat_1 = (estim["lnchprg", "Estimate"] - 0) / estim["lnchprg", "Std. Error"] )
```

```
## [1] -9.152422
```

```r
# p-valores para H0: bhat = 0
2 * (1 - pt(abs(t_bhat_0), n-1)) # p-valor para bhat_0
```

```
## [1] 0
```

```r
2 * (1 - pt(abs(t_bhat_1), n-1)) # p-valor para bhat_1
```

```
## [1] 0
```


## Viola√ß√µes de hip√≥tese
- [Subse√ß√£o 2.7.3 de Heiss (2020)](http://www.urfie.net/read/index.html#page/113), mas usando como exemplo o teste elaborado 1.
- [Simulating a linear model (John Hopkins/Coursera)](https://www.coursera.org/learn/r-programming/lecture/u7in9/simulation-simulating-a-linear-model)
- Na pr√°tica, fazemos regress√µes a partir de observa√ß√µes contidas em bases de dados e n√£o sabemos qual √© o _modelo real_ que gerou essas observa√ß√µes.
- No R, podemos supor um _modelo real_ e simular suas observa√ß√µes no R para analisar o que ocorre quando h√° viola√ß√£o de hip√≥tese de algum modelo econom√©trico ou estimador.
- Usaremos o exemplo dado no Teste Elaborado 1, no qual queremos encontrar a rela√ß√£o das horas de pr√°tica em culin√°ria com o n√∫mero de queimaduras na cozinha.


### Sem viola√ß√£o de hip√≥tese: Exemplo 1
- Sejam {{<math>}}$y${{</math>}} o n√∫mero de queimaduras na cozinha e {{<math>}}$x${{</math>}} o n√∫mero de horas gastas aprendendo a cozinhar.
- Suponha o _modelo real_:
$$ y = a_0 + b_0 x + \varepsilon, \qquad \varepsilon \sim N(0, 2^2) \tag{1}$$
em que {{<math>}}$a_0=50${{</math>}} e {{<math>}}$b_0=-5${{</math>}}.

1. Definindo {{<math>}}$a_0${{</math>}} e {{<math>}}$b_0${{</math>}} e gerando por simula√ß√£o as "observa√ß√µes" de {{<math>}}$x${{</math>}} e {{<math>}}$y${{</math>}}:
    - Apenas para facilitar, geraremos valores aleat√≥rios {{<math>}}$x \sim N(5; 0,5^2)${{</math>}}. Aqui, n√£o importa a distribui√ß√£o de {{<math>}}$x${{</math>}}. 

```r
a0 = 50
b0 = -5
N = 200 # N√∫mero de observa√ß√µes

set.seed(1)
u = rnorm(N, 0, 2) # Desvios: 200 obs. de m√©dia 0 e desv pad 2
x = rnorm(N, 5, 0.5) # Gerando 200 obs. de m√©dia 5 e desv pad 1
y = a0 + b0*x + u # calculando observa√ß√µes y a partir de "e" e "x"

plot(x, y)
```

<img src="/project/rec2301/sec7/_index_files/figure-html/unnamed-chunk-21-1.png" width="672" />
Simulamos as observa√ß√µes {{<math>}}$x${{</math>}} e {{<math>}}$y${{</math>}} que s√£o, na pr√°tica, as informa√ß√µes que observamos.

2. Estimando por MQO os par√¢metros {{<math>}}$\hat{a}${{</math>}} e {{<math>}}$\hat{b}${{</math>}} a partir das observa√ß√µes simuladas de {{<math>}}$y${{</math>}} e {{<math>}}$x${{</math>}}:
    - Um economista sup√¥s a rela√ß√£o entre as vari√°veis pelo seguinte _modelo emp√≠rico_:
    $$ y = a + b x + u, \tag{1a}$$
    assumindo que {{<math>}}$E[u] = 0${{</math>}} e {{<math>}}$E[ux]=0${{</math>}}.
    - Para estimar o modelo por MQO, usamos a fun√ß√£o `lm()`
    

```r
lm(y ~ x) # regredindo por MQO a var. dependente y pela var. x
```

```
## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##      50.463       -5.078
```

- Note que foi poss√≠vel recuperar os par√¢metros populacionais ({{<math>}}$\hat{a} = 50,268 \approx 50 = a_0${{</math>}} e {{<math>}}$\hat{b} = -5,039 \approx -5 = b_0${{</math>}}).


```r
plot(x, y) # Figura de x contra y
abline(a=50, b=-5, col="red") # reta do modelo real
abline(lm(y ~ x), col="blue") # reta estimada a partir das observa√ß√µes
```

<img src="/project/rec2301/sec7/_index_files/figure-html/unnamed-chunk-23-1.png" width="672" />

### Sem viola√ß√£o de hip√≥tese: Exemplo 2
- Agora, no _modelo real_, suponha que o n√∫mero de queimaduras {{<math>}}$y${{</math>}} √© determinado tanto pela quantidade de horas de aprendizado {{<math>}}$x${{</math>}} e pela quantidade de horas gastas cozinhando {{<math>}}$z${{</math>}}:

$$ y = a_0 + b_0 x + c_0 z + u, \qquad u \sim N(0, 2^2) \tag{2} $$
em que {{<math>}}$a_0=50${{</math>}}, {{<math>}}$b_0=-5${{</math>}} e {{<math>}}$c_0=3${{</math>}}. Apenas para facilitar, usaremos geraremos valores aleat√≥rios de {{<math>}}$x \sim N(5; 0,5^2)${{</math>}} e {{<math>}}$z \sim N(1,875; 0,25^2)${{</math>}}. Note que {{<math>}}$z${{</math>}}, por constru√ß√£o, n√£o √© correlacionada com {{<math>}}$x${{</math>}} no _modelo real_.

- Primeiro, vamos simular as observa√ß√µes:

```r
a0 = 50
b0 = -5
c0 = 3
N = 200 # N√∫mero de observa√ß√µes

set.seed(1)
u = rnorm(N, 0, 2) # Desvios: 200 obs. de m√©dia 0 e desv pad 2
x = rnorm(N, 5, 0.5) # Gerando 200 obs. de m√©dia 5 e desv pad 1
z = rnorm(N, 1.875, 0.25) # Gerando 200 obs. de m√©dia 1,875 e desv pad 0.25
y = a0 + b0*x + c0*z + u # calculando observa√ß√µes y a partir de "e", "x" e "z"
```

- Considere que um economista suponha a rela√ß√£o entre as vari√°veis pelo seguinte _modelo emp√≠rico_:
    $$ y = a + b x + u, \tag{2a}$$
    assumindo que {{<math>}}$E[u] = 0${{</math>}} e {{<math>}}$E[ux] = 0${{</math>}}.

- Note que o economista deixou a vari√°vel de horas cozinhando {{<math>}}$z${{</math>}} fora do modelo, ent√£o ela acaba ``entrando'' no erro da estima√ß√£o.
- No entanto, como {{<math>}}$z${{</math>}} n√£o tem rela√ß√£o com {{<math>}}$x${{</math>}}, ent√£o isso n√£o afeta a estimativa de {{<math>}}$\hat{b}${{</math>}}:

```r
cor(x, z) # correla√ß√£o de x e z -> pr√≥xima de 0
```

```
## [1] -0.02625278
```

```r
lm(y ~ x) # estima√ß√£o por MQO
```

```
## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##       56.27        -5.12
```
- Note que {{<math>}}$\hat{b} = -5,12 \approx -5 = b_0${{</math>}}, portanto a estima√ß√£o por MQO conseguiu recuperar o par√¢metro populacional {{<math>}}$b_0${{</math>}}, apesar do economista n√£o ter inclu√≠do {{<math>}}$z${{</math>}} no modelo.
- Grande parte dos estudos econ√¥micos tentam estabelecer a rela√ß√£o/causalidade entre {{<math>}}$y${{</math>}} e {{<math>}}$x${{</math>}}, ent√£o n√£o √© necess√°rio incluir todas poss√≠veis vari√°veis que impactam {{<math>}}$y${{</math>}}, desde que {{<math>}}$E(ux) = 0${{</math>}} (ou seja, que nenhuma vari√°vel explicativa correlacionada com {{<math>}}$x${{</math>}} tenha ``ficado de fora'' e, portanto, compondo o termo de erro).



### Viola√ß√£o de E(ux)=0
- Agora, suponha que, no _modelo real_, quanto mais horas a pessoa pratica culin√°ria, mais ele cozinha (ou seja, {{<math>}}$x${{</math>}} est√° relacionada com {{<math>}}$z${{</math>}}).
    - Considere que {{<math>}}$z \sim N(1,875x; (0,25)^2)${{</math>}}:
    

```r
set.seed(1)
e = rnorm(N, 0, 2) # Desvios: 200 obs. de m√©dia 0 e desv pad 2
x = rnorm(N, 5, 0.5) # Gerando 200 obs. de m√©dia 5 e desv pad 1
z = rnorm(N, 1.875*x, 0.25) # Gerando 200 obs. de m√©dia 1,875x e desv pad 0.25x
y = a0 + b0*x + c0*z + e # calculando observa√ß√µes y a partir de "e", "x" e "z"
cor(x, z) # correla√ß√£o de x e z
```

```
## [1] 0.9618748
```

- Note que, agora, {{<math>}}$x${{</math>}} e {{<math>}}$z${{</math>}} s√£o consideravalmente correlacionados
- Vamos estimar o _modelo emp√≠rico_:
    $$ y = a + b x + u,$$
    assumindo que {{<math>}}$E[u] = 0${{</math>}} e {{<math>}}$E[ux]=0${{</math>}}.
    

```r
lm(y ~ x) # estima√ß√£o por MQO
```

```
## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##     50.6406       0.5053
```

- Observe que {{<math>}}$\hat{b} = 0,5 \neq -5 = b_0${{</math>}}. Isto se d√° porque {{<math>}}$z${{</math>}} n√£o foi inclu√≠do no modelo e, portanto, ele acaba compondo o desvio {{<math>}}$\hat{u}${{</math>}}. Como {{<math>}}$z${{</math>}} √© correlacionado com {{<math>}}$x${{</math>}}, ent√£o {{<math>}}$E(ux)\neq 0${{</math>}} (violando a hip√≥tese do MQO).
- Observe que, se inclu√≠ssemos a vari√°vel {{<math>}}$z${{</math>}} na estima√ß√£o, conseguir√≠amos recuperar {{<math>}}$\hat{b} \approx b_0${{</math>}}:


```r
lm(y ~ x + z)
```

```
## 
## Call:
## lm(formula = y ~ x + z)
## 
## Coefficients:
## (Intercept)            x            z  
##      50.435       -5.953        3.470
```

### Viola√ß√£o de E(u)=0
- Agora, consideraremos que {{<math>}}$E[u] = k${{</math>}}, sendo {{<math>}}$k \neq 0${{</math>}} uma constante.
- Assuma que {{<math>}}$k = 10${{</math>}}:

```r
a0 = 50
b0 = -5
k = 10

set.seed(1)
u = rnorm(N, k, 2) # Desvios: 200 obs. de m√©dia k e desv pad 2
x = rnorm(N, 5, 0.5) # Gerando 200 obs. de m√©dia 5 e desv pad 1
y = a0 + b0*x + u # calculando observa√ß√µes y a partir de "e" e "x"
```
- Caso um economista considere um _modelo emp√≠rico_ com {{<math>}}$E[u] = 0${{</math>}}, segue que:

```r
lm(y ~ x) # estima√ß√£o por MQO
```

```
## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##      60.463       -5.078
```
- Note que o fato de {{<math>}}$E[u] \neq 0${{</math>}} afeta apenas a estima√ß√£o de {{<math>}}$\hat{a} \neq a_0${{</math>}}, por√©m n√£o afeta a de {{<math>}}$\hat{b} \approx b_0${{</math>}}, que √© normalmente o par√¢metro de interesse em estudos econ√¥micos.


### Viola√ß√£o de Homocedasticidade
- Agora, consideraremos que {{<math>}}$u \sim N(0, (2x)^2)${{</math>}}, ou seja, a vari√¢ncia cresce com {{<math>}}$x${{</math>}} ({{<math>}}$u${{</math>}} n√£o √© independente de {{<math>}}$x${{</math>}}/n√£o vale homocedasticidade).

```r
a0 = 50
b0 = -5

set.seed(1)
x = rnorm(N, 5, 0.5) # Gerando 200 obs. de m√©dia 5 e desv pad 1
u = rnorm(N, 0, 2*x) # Desvios: 200 obs. de m√©dia k e desv pad 2x
y = a0 + b0*x + u # calculando observa√ß√µes y a partir de "e" e "x"

lm(y ~ x) # estima√ß√£o por MQO
```

```
## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##      51.221       -5.166
```
- Note que, mesmo com heterocesdasticidade, √© poss√≠vel recuperar {{<math>}}$\hat{b} \approx b_0${{</math>}}. Mas, observe tamb√©m que, se a amostra for pequena, mais prov√°vel √© que {{<math>}}$\hat{b} \neq b_0${{</math>}}. Teste diversas vezes para {{<math>}}$N${{</math>}} menores.



## Qualidade do ajuste
- [Se√ß√£o 2.3 de Heiss (2020)](http://www.urfie.net/read/index.html#page/101)
- A soma de quadrados total (SQT), a soma de quadrados explicada (SQE) e a soma de quadrados dos res√≠duos (SQR) podem ser escritos como:

{{<math>}}\begin{align}
    SQT &= \sum^n_{i=1}{(y_i - \bar{y})^2} = (n-1) . Var(y) \tag{2.10}\\
    SQE &= \sum^n_{i=1}{(\hat{y}_i - \bar{y})^2} = (n-1) . Var(\hat{y}) \tag{2.11}\\
    SQR &= \sum^n_{i=1}{(\hat{u}_i - 0)^2} = (n-1) . Var(\hat{u}) \tag{2.12}
\end{align}{{</math>}}
em que {{<math>}}$Var(x) = \frac{1}{n-1} \sum^n_{i=1}{(x_i - \bar{x})^2}${{</math>}}.

- Wooldridge (2006) define o coeficiente de determina√ß√£o como:
{{<math>}}\begin{align}
    R^2 &= \frac{SQE}{SQT} = 1 - \frac{SQR}{SQT}\\
        &= \frac{Var(\hat{y})}{Var(y)} = 1 - \frac{Var(\hat{u})}{Var(y)} \tag{2.13}
\end{align}{{</math>}}
pois {{<math>}}$SQT = SQE + SQR${{</math>}}.


```r
# Calculando R^2 de tr√™s maneiras:
var(sal_hat) / var(sal)
```

```
## [1] 0.01318862
```

```r
1 - var(u_hat)/var(sal)
```

```
## [1] 0.01318862
```

```r
cor(sal, sal_hat)^2 # correla√ß√£o ao quadrado da vari√°vel dependente com valores ajustados
```

```
## [1] 0.01318862
```

- Para obter o {{<math>}}$R^2${{</math>}} de forma mais conveniente, pode-se usar a fun√ß√£o `summary()` sobre o objeto de resultado da regress√£o. Esta fun√ß√£o fornece uma visualiza√ß√£o dos resultados mais detalhada, incluindo o {{<math>}}$R^2${{</math>}}:

```r
summary(CEOregres)
```

```
## 
## Call:
## lm(formula = salary ~ roe, data = ceosal1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1160.2  -526.0  -254.0   138.8 13499.9 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   963.19     213.24   4.517 1.05e-05 ***
## roe            18.50      11.12   1.663   0.0978 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1367 on 207 degrees of freedom
## Multiple R-squared:  0.01319,	Adjusted R-squared:  0.008421 
## F-statistic: 2.767 on 1 and 207 DF,  p-value: 0.09777
```



{{< cta cta_text="üëâ Seguir para Regress√£o M√∫ltipla" cta_link="../sec8" >}}
