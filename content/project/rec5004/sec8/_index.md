---
date: "2018-09-09T00:00:00Z"
# icon: book
# icon_pack: fas
linktitle: Multiple Regression
summary: This page explores OLS Multiple Regression, including with qualitative regressors. It also includes examples and code snippets to demonstrate the concepts being discussed. 
title: Multiple Regression
weight: 8
output: md_document
type: book
---





## Opera√ß√µes matriciais no R
- [Vectorized operations (John Hopkins/Coursera)](https://www.coursera.org/learn/r-programming/lecture/nobfZ/vectorized-operations)
- Ao utilizar as opera√ß√µes matem√°ticas convencionais em vetores, cada elemento √© operacionalizado com o elemento na mesma posi√ß√£o do outro vetor

```r
x = 1:4

x + x # soma de cada elemento na mesma posi√ß√£o
```

```
## [1] 2 4 6 8
```

```r
x + 2 # soma de de cada elemento com um mesmo escalar
```

```
## [1] 3 4 5 6
```

```r
x * x # multiplica√ß√£o de cada elemento na mesma posi√ß√£o
```

```
## [1]  1  4  9 16
```

```r
x / x # divis√£o de cada elemento na mesma posi√ß√£o
```

```
## [1] 1 1 1 1
```


- Al√©m disso, podemos fazer
  - **Transposta de uma matriz ou vetor**: fun√ß√£o `t()`
  - **Multiplica√ß√£o matricial ou vetorial (produto interno)**: operador `%*%`
  - **Inversa de uma matriz (quadrada)**: fun√ß√£o `solve()`


```r
# Opera√ß√µes vetoriais
x %*% x # x vetor-linha / x vetor-coluna
```

```
##      [,1]
## [1,]   30
```

```r
x %*% t(x) # x vetor-coluna / x vetor-linha (altera ambos, mas t() s√≥ no 2o)
```

```
##      [,1] [,2] [,3] [,4]
## [1,]    1    2    3    4
## [2,]    2    4    6    8
## [3,]    3    6    9   12
## [4,]    4    8   12   16
```

- Por padr√£o, o R considera que o 1¬∫ vetor √© um vetor-linha e o 2¬∫ √© um vetor-coluna quando fazemos uma multiplica√ß√£o vetorial.
- Dado que adotamos vetores-coluna como padr√£o, sugiro "for√ßar" um vetor em linha ou em coluna via fun√ß√£o `matrix()`.


```r
# Transformando em vetor-coluna
x_col = matrix(x, ncol=1)
x_col
```

```
##      [,1]
## [1,]    1
## [2,]    2
## [3,]    3
## [4,]    4
```

```r
# Opera√ß√µes vetoriais
t(x_col) %*% x_col # produto interno
```

```
##      [,1]
## [1,]   30
```

```r
x_col %*% t(x_col) # produto externo
```

```
##      [,1] [,2] [,3] [,4]
## [1,]    1    2    3    4
## [2,]    2    4    6    8
## [3,]    3    6    9   12
## [4,]    4    8   12   16
```

</br>

- O mesmo √© v√°lido para matrizes:

```r
# Como exemplo, criaremos matriz X de dimens√£o 4x2
X = matrix(1:8, nrow=4, ncol=2)
X
```

```
##      [,1] [,2]
## [1,]    1    5
## [2,]    2    6
## [3,]    3    7
## [4,]    4    8
```

```r
# Transposta de X (2x4)
t(X)
```

```
##      [,1] [,2] [,3] [,4]
## [1,]    1    2    3    4
## [2,]    5    6    7    8
```

```r
# Produto matricial X'X (2x2)
t(X) %*% X
```

```
##      [,1] [,2]
## [1,]   30   70
## [2,]   70  174
```

```r
# Inversa de X'X (2x2)
solve( t(X) %*% X )
```

```
##          [,1]     [,2]
## [1,]  0.54375 -0.21875
## [2,] -0.21875  0.09375
```

- Tamb√©m podemos criar uma matrix identidade usando a fun√ß√£o `diag()` e informando um n√∫mero inteiro

```r
# Matriz identidade de dimens√£o 4
I = diag(4)
I
```

```
##      [,1] [,2] [,3] [,4]
## [1,]    1    0    0    0
## [2,]    0    1    0    0
## [3,]    0    0    1    0
## [4,]    0    0    0    1
```

```r
# diag() pode alterar valores da diagonal de uma matriz existente
diag(I) = 1:4
I
```

```
##      [,1] [,2] [,3] [,4]
## [1,]    1    0    0    0
## [2,]    0    2    0    0
## [3,]    0    0    3    0
## [4,]    0    0    0    4
```

</br>

## MQO na forma matricial

- [Se√ß√£o 3.2 de Heiss (2020)](http://www.urfie.net/read/index.html#page/119)


### Nota√ß√µes

- Para mais detalhes sobre a forma matricial do MQO, ver Ap√™ndice E de Wooldridge (2006)
- Considere o modelo multivariado com {{<math>}}$K${{</math>}} regressores para a observa√ß√£o {{<math>}}$i${{</math>}}:
$$ y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_K x_{iK} + \varepsilon_i, \qquad i=1, 2, ..., N \tag{E.1} $$
em que {{<math>}}$N${{</math>}} √© o n√∫mero de observa√ß√µes.

- Defina o vetor-coluna de par√¢metros, {{<math>}}$\boldsymbol{\beta}${{</math>}}, e o vetor-linha de vari√°veis independentes da observa√ß√£o {{<math>}}$i${{</math>}}, {{<math>}}$\boldsymbol{x}'_i${{</math>}} (min√∫sculo):
{{<math>}}$$ \underset{1 \times K}{\boldsymbol{x}'_i} = \left[ \begin{matrix} 1 & x_{i1} & x_{i2} & \cdots & x_{iK}  \end{matrix} \right]  \qquad \text{e} \qquad  \underset{(K+1) \times 1}{\boldsymbol{\beta}} = \left[ \begin{matrix} \beta_0 \\ \beta_1 \\ \beta_2 \\ \vdots \\ \beta_K \end{matrix} \right],$${{</math>}}

- Note que o produto interno {{<math>}}$\boldsymbol{x}'_i \boldsymbol{\beta}${{</math>}} √©:

{{<math>}}\begin{align} \underset{1 \times 1}{\boldsymbol{x}'_i \boldsymbol{\beta}} &= \left[ \begin{matrix} 1 & x_{i1} & x_{i2} & \cdots & x_{iK}  \end{matrix} \right]  \left[ \begin{matrix} \beta_0 \\ \beta_1 \\ \beta_2 \\ \vdots \\ \beta_K \end{matrix} \right]\\
&= 1.\beta_0 + x_{i1} \beta_1  + x_{i2} \beta_2 + \cdots + x_{iK} \beta_K, \end{align}{{</math>}}

- Logo, a equa√ß√£o (3.1) pode ser reescrita, para {{<math>}}$i=1, 2, ..., N${{</math>}}, como

$$ y_i = \underbrace{\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_K x_{iK}}_{\boldsymbol{x}'_i \boldsymbol{\beta}} + \varepsilon_i = \boldsymbol{x}'_i \boldsymbol{\beta} + \varepsilon_i, \tag{E.2} $$

- Considere {{<math>}}$\boldsymbol{X}${{</math>}} a matriz de todas {{<math>}}$N${{</math>}} observa√ß√µes para as {{<math>}}$K+1${{</math>}} vari√°veis explicativas:

{{<math>}}$$ \underset{N \times (K+1)}{\boldsymbol{X}} = \left[ \begin{matrix} \boldsymbol{x}_1 \\ \boldsymbol{x}_2 \\ \vdots \\ \boldsymbol{x}_N \end{matrix} \right] = \left[ \begin{matrix} 1 & x_{11} & x_{12} & \cdots & x_{1K}   \\ 1 & x_{21} & x_{22} & \cdots & x_{2K} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 1 & x_{N1} & x_{N2} & \cdots & x_{NK} \end{matrix} \right] , $${{</math>}}

- Agora, podemos "empilhar" as equa√ß√µes (3.2) para todo {{<math>}}$i=1, 2, ..., N${{</math>}} e obtemos:

{{<math>}}\begin{align} \boldsymbol{y} &= \boldsymbol{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon} \tag{E.3} \\
&= \left[ \begin{matrix} 1 & x_{11} & x_{12} & \cdots & x_{1K}   \\ 1 & x_{21} & x_{22} & \cdots & x_{2K} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 1 & x_{N1} & x_{N2} & \cdots & x_{NK} \end{matrix} \right] \left[ \begin{matrix} \beta_0 \\ \beta_1 \\ \beta_2 \\ \vdots \\ \beta_K \end{matrix} \right] + \left[ \begin{matrix}\varepsilon_1 \\ \varepsilon_2 \\ \vdots \\ \varepsilon_N \end{matrix} \right]   \\
&= \left[ \begin{matrix} \beta_0. 1 + \beta_1 x_{11} + \beta_2 x_{12} + ... + \beta_K x_{1K} \\ \beta_0 .1 + \beta_1 x_{21} + \beta_2 x_{22} + ... + \beta_K x_{2K} \\ \vdots \\ \beta_0. 1 + \beta_1 x_{N1} + \beta_2 x_{N2} + ... + \beta_K x_{NK} \end{matrix} \right] + \left[ \begin{matrix}\varepsilon_1 \\ \varepsilon_2 \\ \vdots \\ \varepsilon_N \end{matrix} \right]\\
&= \left[ \begin{matrix} \beta_0. 1 + \beta_1 x_{11} + \beta_2 x_{12} + ... + \beta_K x_{1K} + \varepsilon_1 \\ \beta_0 .1 + \beta_1 x_{21} + \beta_2 x_{22} + ... + \beta_K x_{2K} + \varepsilon_2 \\ \vdots \\ \beta_0. 1 + \beta_1 x_{N1} + \beta_2 x_{N2} + ... + \beta_K x_{NK} + \varepsilon_N \end{matrix} \right]\\
&= \left[ \begin{matrix}y_1 \\ y_2 \\ \vdots \\ y_N \end{matrix} \right] = \boldsymbol{y} \end{align}{{</math>}}

### Estimativas de MQO

{{<math>}}$$ \hat{\boldsymbol{\beta}} = \left[ \begin{matrix} \hat{\beta}_0 \\ \hat{\beta}_1 \\ \hat{\beta}_2 \\ \vdots \\ \hat{\beta}_K \end{matrix} \right] = (\boldsymbol{X}'\boldsymbol{X})^{-1} \boldsymbol{X}' \boldsymbol{y} \tag{3.2} $${{</math>}}



### Valores preditos
{{<math>}}$$ \hat{\boldsymbol{y}} = \boldsymbol{X} \hat{\boldsymbol{\beta}}  $${{</math>}}


### Res√≠duos
{{<math>}}$$ \hat{\boldsymbol{\varepsilon}} = \boldsymbol{y} - \hat{\boldsymbol{y}} \tag{3.3}  $${{</math>}}



### Matriz de vari√¢ncias-covari√¢ncias dos erros
A Matriz de vari√¢ncias-covari√¢ncias dos erros relaciona um termo de erro, {{<math>}}$\varepsilon_{i}${{</math>}}, com todos os demais termos de erro {{<math>}}$\varepsilon_{j}${{</math>}}, para todo {{<math>}}$j = 1, ..., N${{</math>}}.

Na matriz de covari√¢ncia de erro, cada linha representa um {{<math>}}$\varepsilon_{i}${{</math>}} e cada coluna representa um {{<math>}}$\varepsilon_{j}${{</math>}}. Seus elementos representam a covari√¢ncia entre 
{{<math>}}$\varepsilon_{i}${{</math>}} e {{<math>}}$\varepsilon_{j}${{</math>}}, sendo que pode haver {{<math>}}$\varepsilon_{i} = \varepsilon_{j}${{</math>}} (que, neste caso, torna-se vari√¢ncia):

{{<math>}}$$ cov(\boldsymbol{\varepsilon}) = \underset{N \times N}{\boldsymbol{\Sigma}} = 
\left[ \begin{array}{cccc}
var(\varepsilon_{1}) & cov(\varepsilon_{1}, \varepsilon_{2}) & \cdots & cov(\varepsilon_{1}, \varepsilon_{N}) \\
cov(\varepsilon_{2}, \varepsilon_{1}) & var(\varepsilon_{2}) & \cdots & cov(\varepsilon_{2}, \varepsilon_{N}) \\
\vdots & \vdots & \ddots & \vdots \\
cov(\varepsilon_{N}, \varepsilon_{1}) & cov(\varepsilon_{N}, \varepsilon_{2}) & \cdots & var(\varepsilon_{N}) 
\end{array} \right]$${{</math>}}

Como assumimos amostragem aleat√≥ria, a covari√¢ncia entre dois indiv√≠duos distintos {{<math>}}($i \neq j$){{</math>}} √©  
{{<math>}}$$ cov(\varepsilon_{i}, \varepsilon_{j}) = 0,  \qquad \text{para todo } i \neq j.$${{</math>}}

Logo, 
{{<math>}}$$ \boldsymbol{\Sigma} = 
\left[ \begin{array}{cccc}
var(\varepsilon_{1}) & 0 & \cdots & 0 \\
0 & var(\varepsilon_{2}) & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & var(\varepsilon_{N}) 
\end{array} \right]$${{</math>}}


Como tamb√©m assumimos homocedasticidade, {{<math>}}$ var(\varepsilon_i) = \sigma^2,\ \forall i${{</math>}}, ent√£o:

{{<math>}}$$ \boldsymbol{\Sigma} = 
\left[ \begin{array}{cccc}
\sigma^2 & 0 & \cdots & 0 \\
0 & \sigma^2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \sigma^2 
\end{array} \right] = \sigma^2 \begin{bmatrix} 1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1  \end{bmatrix} = \sigma^2 I_N $${{</math>}}


### Vari√¢ncia do termo de erro

Como n√£o conhecemos a vari√¢ncia do termo de erro {{<math>}}$\sigma^2${{</math>}}, precisamos estim√°-la usando:

{{<math>}}$$ \hat{\sigma}^2 = \frac{\hat{\boldsymbol{\varepsilon}}'\hat{\boldsymbol{\varepsilon}}}{N-K-1}  $${{</math>}}



### Matriz de vari√¢ncias-covari√¢ncias do estimador

- A matriz de vari√¢ncias-covari√¢ncias do estimador tem a seguinte estrutura
{{<math>}}$$ V(\hat{\boldsymbol{\beta}}) 
= \begin{bmatrix} var(\hat{\beta}_0) & cov(\hat{\beta}_0, \hat{\beta}_1) & \cdots &  cov(\hat{\beta}_0, \hat{\beta}_K) \\
cov(\hat{\beta}_1, \hat{\beta}_0) & var(\hat{\beta}_1) & \cdots &  cov(\hat{\beta}_1, \hat{\beta}_K) \\
\vdots & \vdots & \ddots & \vdots \\
cov(\hat{\beta}_K, \hat{\beta}_0) & cov(\hat{\beta}_K, \hat{\beta}_1) & \cdots &  var(\hat{\beta}_K) \end{bmatrix} $${{</math>}}

- Essa matriz pode ser obtida usando:
{{<math>}}$$ V(\hat{\boldsymbol{\beta}}) = (\boldsymbol{X}'\boldsymbol{X})^{-1} \boldsymbol{X}' \boldsymbol{\Sigma} \boldsymbol{X} (\boldsymbol{X}'\boldsymbol{X})^{-1}, $${{</math>}}
mas como MQO sup√µe {{<math>}}$ \boldsymbol{\Sigma} = \sigma^2 \boldsymbol{I} ${{</math>}}, ent√£o a matriz de vari√¢ncias-covari√¢ncias do estimador pode ser simplificada:

{{<math>}}\begin{align} V(\hat{\boldsymbol{\beta}}) 
&= (\boldsymbol{X}'\boldsymbol{X})^{-1} \boldsymbol{X}' \boldsymbol{\Sigma} \boldsymbol{X} (\boldsymbol{X}'\boldsymbol{X})^{-1} \\ 
&= (\boldsymbol{X}'\boldsymbol{X})^{-1} \boldsymbol{X}' \left[ \sigma^2 \boldsymbol{I} \right] \boldsymbol{X} (\boldsymbol{X}'\boldsymbol{X})^{-1} \\
&= \sigma^2 (\boldsymbol{X}'\boldsymbol{X})^{-1} \boldsymbol{X}' \boldsymbol{X} (\boldsymbol{X}'\boldsymbol{X})^{-1} \\
&= \sigma^2 (\boldsymbol{X}'\boldsymbol{X})^{-1} \end{align}{{</math>}}


### Erros-padr√£o do estimador
Os erros padr√£o do estimador podem ser obtidos tomando a raiz quadrada da diagonal principal da matriz de vari√¢ncia-covari√¢ncia do estimador:

{{<math>}}$$\text{se}(\hat{\boldsymbol{\beta}}) = \sqrt{\text{diag}(V(\hat{\boldsymbol{\beta}}))} = \begin{bmatrix} \sqrt{\text{var}(\hat{\beta}_0)} \\ \sqrt{\text{var}(\hat{\beta}_1)} \\ \vdots \\ \sqrt{\text{var}(\hat{\beta}_K)} \end{bmatrix} = \begin{bmatrix} \text{se}(\hat{\beta}_0) \\ \text{se}(\hat{\beta}_1) \\ \vdots \\ \text{se}(\hat{\beta}_K) \end{bmatrix} $${{</math>}}



### Teste _t_

- [Se√ß√£o 4.1 de Heiss (2020)](http://www.urfie.net/read/index.html#page/127)

- Ap√≥s a estima√ß√£o, √© importante testar hip√≥teses na forma
$$ H_0: \ \beta_k = h_k \tag{4.1} $$
tal que {{<math>}}$h_k${{</math>}} √© uma constante, e {{<math>}}$k${{</math>}} √© um dos {{<math>}}$K+1${{</math>}} par√¢metros estimados.

- Esta hip√≥tese pode ser testada pelo teste _t_:
$$ t_k = \frac{\hat{\beta}_k - h_k}{\text{se}(\hat{\beta}_k)} \tag{4.4} $$

- Por padr√£o, as rotinas de softwares estat√≠sticos realizam o teste bicaudal com {{<math>}}$h_k=0${{</math>}} para testar se a estimativa {{<math>}}$\hat{\beta}_k${{</math>}} √© estatisticamente significante (efeito estatisticamente diferente de zero sobre a vari√°vel dependente):

{{<math>}}\begin{align} 
H_0: \ \beta_k &= 0, \tag{4.5}\\
t_{\hat{\beta}_k} &= \frac{\hat{\beta}_k}{\text{se}(\hat{\beta}_k)} \tag{4.6}
\end{align}{{</math>}}

- H√° tr√™s formas de avaliar essa hip√≥tese.
- **(i)** A primeira √© por meio da compara√ß√£o da **estat√≠stica _t_** com o valor cr√≠tico (cv), dado um n√≠vel de signific√¢ncia {{<math>}}$\alpha${{</math>}}:
{{<math>}}$$ \text{Rejeitamos H}_0 \text{ se:} \qquad | t_{\hat{\beta}_k} | > \text{cv}_{\scriptscriptstyle{1-\alpha}}. $${{</math>}}


- Frequentemente, utiliza-se {{<math>}}$\alpha = 5\%${{</math>}}, cujo valor cr√≠tico tende a ficar pr√≥ximo de 2,0 para quantidades razo√°veis de graus de liberdade (e se aproxima ao valor cr√≠tico de 1,96 da distribui√ß√£o normal).

</br>

- **(ii)** Outra maneira de avaliar a hip√≥tese nula √© via **p-valor**, que indica o qu√£o prov√°vel √© que  {{<math>}}$\hat{\beta}_k${{</math>}} n√£o seja um valor extremo (ou seja, o qu√£o prov√°vel √© que a estimativa seja igual a {{<math>}}$h_k = 0${{</math>}}).
{{<math>}}$$ p_{\hat{\beta}_k} = 2.\Phi_{t_{\small{(N-K-1)}}}(-|t_{\hat{\beta}_k}|), \tag{4.7} $${{</math>}}
em que {{<math>}}$\Phi_{t_{\small{(N-K-1)}}}(\cdot)${{</math>}} √© a cdf de uma distribui√ß√£o _t_ com {{<math>}}$(N-K-1)${{</math>}} graus de liberdade.

<center><img src="../t_test.png" width=50%></center>

- Portanto, rejeitamos {{<math>}}$H_0${{</math>}} quando o p-valor for menor do que um n√≠vel de signific√¢ncia {{<math>}}$\alpha${{</math>}}:
{{<math>}}$$ \text{Rejeitamos H}_0 \text{ se:} \qquad p_{\hat{\beta}_k} \le \alpha $${{</math>}}


</br>

- **(iii)** A terceira maneira de avaliar a hip√≥tese nula √© via c√°lculo do **intervalo de confian√ßa**:
$$ \text{CI}_\alpha = \hat{\beta}_k\ \pm\ \text{cv}_{\scriptscriptstyle{1-\alpha}} . \text{se}(\hat{\beta}_k) \tag{4.8} $$
- Rejeitamos a hip√≥tese nula, neste caso, quando {{<math>}}$h_k${{</math>}} estiver fora do intervalo de confian√ßa.



</br>



## Estima√ß√£o MQO multivariado

### Estima√ß√£o via `lm()`

- [Se√ß√£o 3.1 de Heiss (2020)](http://www.urfie.net/read/index.html#page/115)

- Para estimar um modelo multivariado no R, podemos usar a fun√ß√£o `lm()`:
  - O til (`~`) separa a a vari√°vel dependente das vari√°veis independentes
  - As vari√°veis independentes precisam ser separadas por um `+`
  - O intercepto ({{<math>}}$\beta_0${{</math>}}) √© inclu√≠do automaticamente pela fun√ß√£o `lm()` -- para retir√°-lo, √© preciso incluir a "vari√°vel" `0` na f√≥rmula.


#### Exemplo 3.1: Determinantes da Nota M√©dia em Curso Superior nos EUA
- Sejam as vari√°veis
    - `colGPA` (_college GPA_): a nota m√©dia em um curso superior,
    - `hsGPA` (_high school GPA_): a nota m√©dio do ensino m√©dio, e
    - `ACT` (_achievement test score_): a nota de avalia√ß√£o de conhecimentos para ingresso no ensino superior.
- Usando a base `gpa1` do pacote `wooldridge`, vamos estimar o seguinte modelo:

$$ \text{colGPA} = \beta_0 + \beta_1 \text{hsGPA} + \beta_2 \text{ACT} + \varepsilon $$


```r
# Acessando a base de dados gpa1
data(gpa1, package = "wooldridge")

# Estimando o modelo
reg = lm(colGPA ~ hsGPA + ACT, data = gpa1)
reg
```

```
## 
## Call:
## lm(formula = colGPA ~ hsGPA + ACT, data = gpa1)
## 
## Coefficients:
## (Intercept)        hsGPA          ACT  
##    1.286328     0.453456     0.009426
```

- Note que podemos ver mais detalhes da estima√ß√£o usando a fun√ß√£o `summary()` no objeto resultante da fun√ß√£o `lm()`

```r
summary(reg)
```

```
## 
## Call:
## lm(formula = colGPA ~ hsGPA + ACT, data = gpa1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.85442 -0.24666 -0.02614  0.28127  0.85357 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 1.286328   0.340822   3.774 0.000238 ***
## hsGPA       0.453456   0.095813   4.733 5.42e-06 ***
## ACT         0.009426   0.010777   0.875 0.383297    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3403 on 138 degrees of freedom
## Multiple R-squared:  0.1764,	Adjusted R-squared:  0.1645 
## F-statistic: 14.78 on 2 and 138 DF,  p-value: 1.526e-06
```

- Podemos extrair apenas a matriz 'Coefficients' usando `coef()` ou `$coef`

```r
# Coefficients
coef(summary(reg))
```

```
##                Estimate Std. Error   t value     Pr(>|t|)
## (Intercept) 1.286327767 0.34082212 3.7741910 2.375872e-04
## hsGPA       0.453455885 0.09581292 4.7327219 5.421580e-06
## ACT         0.009426012 0.01077719 0.8746263 3.832969e-01
```

```r
summary(reg)$coef
```

```
##                Estimate Std. Error   t value     Pr(>|t|)
## (Intercept) 1.286327767 0.34082212 3.7741910 2.375872e-04
## hsGPA       0.453455885 0.09581292 4.7327219 5.421580e-06
## ACT         0.009426012 0.01077719 0.8746263 3.832969e-01
```

```r
# note que se n√£o usarmos summary(), temos apenas as estimativas
coef(reg)
```

```
## (Intercept)       hsGPA         ACT 
## 1.286327767 0.453455885 0.009426012
```

- Al√©m disso, podemos extrair a matriz de vari√¢ncias-covari√¢ncias do estimador:

```r
vcov(reg)
```

```
##              (Intercept)         hsGPA           ACT
## (Intercept)  0.116159717 -0.0226063687 -0.0015908486
## hsGPA       -0.022606369  0.0091801149 -0.0003570767
## ACT         -0.001590849 -0.0003570767  0.0001161478
```



### Estima√ß√£o Anal√≠tica no R (parte 1)

#### Exemplo - Determinantes da Nota M√©dia em Curso Superior nos EUA
- Queremos estimar o modelo:
$$ \text{colGPA} = \beta_0 + \beta_1 \text{hsGPA} + \beta_2 \text{ACT} + \varepsilon $$

- A partir da base de dados `gpa1`, vamos criar o vetor da vari√°vel dependente `y` e a matrix das vari√°veis independentes `X`:


```r
# Acessando a base de dados gpa1
data(gpa1, package = "wooldridge")

# Criando o vetor y
y = as.matrix(gpa1[,"colGPA"]) # transformando coluna de data frame em matriz
head(y)
```

```
##      [,1]
## [1,]  3.0
## [2,]  3.4
## [3,]  3.0
## [4,]  3.5
## [5,]  3.6
## [6,]  3.0
```

```r
# Criando a matriz de covariadas X com primeira coluna de 1's
X = cbind( 1, gpa1[, c("hsGPA", "ACT")] ) # juntando 1's com as covariadas
X = as.matrix(X) # transformando em matriz
head(X)
```

```
##   1 hsGPA ACT
## 1 1   3.0  21
## 2 1   3.2  24
## 3 1   3.6  26
## 4 1   3.5  27
## 5 1   3.9  28
## 6 1   3.4  25
```

```r
# Pegando valores N e K
N = nrow(gpa1)
K = ncol(X) - 1
N
```

```
## [1] 141
```

```r
K
```

```
## [1] 2
```

##### 1. Estimativas de MQO {{<math>}}$\hat{\boldsymbol{\beta}}${{</math>}}

```r
bhat = solve( t(X) %*% X ) %*% t(X) %*% y
bhat
```

```
##              [,1]
## 1     1.286327767
## hsGPA 0.453455885
## ACT   0.009426012
```


##### 2. Valores preditos/ajustados {{<math>}}$\hat{\boldsymbol{y}}${{</math>}}

```r
yhat = X %*% bhat
head(yhat)
```

```
##       [,1]
## 1 2.844642
## 2 2.963611
## 3 3.163845
## 4 3.127926
## 5 3.318734
## 6 3.063728
```


##### 3. Res√≠duos {{<math>}}$\hat{\boldsymbol{\varepsilon}}${{</math>}}

```r
ehat = y - yhat
head(ehat)
```

```
##          [,1]
## 1  0.15535832
## 2  0.43638918
## 3 -0.16384523
## 4  0.37207430
## 5  0.28126580
## 6 -0.06372813
```


##### 4. Vari√¢ncia do termo de erro {{<math>}}$\hat{\sigma}^2${{</math>}}
Como {{<math>}}$\hat{\sigma}^2${{</math>}} √© um escalar, √© conveniente transformar a "matriz 1x1" em um n√∫mero usando `as.numeric()`:

```r
sig2hat = as.numeric( t(ehat) %*% ehat / (N-K-1) )
sig2hat
```

```
## [1] 0.1158148
```


##### 5. Matriz de vari√¢ncias-covari√¢ncias do estimador {{<math>}}$\text{V}(\hat{\boldsymbol{\beta}})${{</math>}}

```r
Vbhat = sig2hat * solve( t(X) %*% X )
Vbhat
```

```
##                  1         hsGPA           ACT
## 1      0.116159717 -0.0226063687 -0.0015908486
## hsGPA -0.022606369  0.0091801149 -0.0003570767
## ACT   -0.001590849 -0.0003570767  0.0001161478
```


##### 6. Erros-padr√£o do estimador {{<math>}}$\text{se}(\hat{\boldsymbol{\beta}})${{</math>}}

```r
se_bhat = sqrt( diag(Vbhat) )
se_bhat
```

```
##          1      hsGPA        ACT 
## 0.34082212 0.09581292 0.01077719
```


##### 7. Estat√≠stica _t_

```r
# C√°lculo da estat√≠stica t
t_bhat = bhat / se_bhat
t_bhat
```

```
##            [,1]
## 1     3.7741910
## hsGPA 4.7327219
## ACT   0.8746263
```


##### 8. Avaliando as hip√≥teses nulas

```r
# defini√ß√£o do n√≠vel de signific√¢ncia
alpha = 0.05
cv = qt(1 - alpha/2, N-K-1) # valor cr√≠tico de teste bicaudal
cv
```

```
## [1] 1.977304
```

```r
# (i) Comparando estat√≠stica t com o valor cr√≠tico
abs(t_bhat) > cv # avaliando H0
```

```
##        [,1]
## 1      TRUE
## hsGPA  TRUE
## ACT   FALSE
```

```r
# (ii) Comparando p-valor com o n√≠vel de signific√¢ncia de 5%
p_bhat = 2 * pt(-abs(t_bhat), N-K-1)
round(p_bhat, 5) # arredondando para facilitar visualiza√ß√£o
```

```
##          [,1]
## 1     0.00024
## hsGPA 0.00001
## ACT   0.38330
```

```r
p_bhat < 0.05 # avaliando H0
```

```
##        [,1]
## 1      TRUE
## hsGPA  TRUE
## ACT   FALSE
```

```r
# (ii) Verificando se zero (0) est√° fora do intervalo de confian√ßa
ci = cbind(bhat - cv*se_bhat, bhat + cv*se_bhat) # avaliando H0
ci
```

```
##              [,1]       [,2]
## 1      0.61241898 1.96023655
## hsGPA  0.26400467 0.64290710
## ACT   -0.01188376 0.03073578
```


##### Comparando estima√ß√µes via `lm()` e anal√≠tica
- Resultados calculados analiticamente ("na m√£o")

```r
round( cbind(bhat, se_bhat, t_bhat, p_bhat), 4 ) # coeficientes
```

```
##              se_bhat              
## 1     1.2863  0.3408 3.7742 0.0002
## hsGPA 0.4535  0.0958 4.7327 0.0000
## ACT   0.0094  0.0108 0.8746 0.3833
```

```r
round(ci, 4) # intervalos de confian√ßa
```

```
##          [,1]   [,2]
## 1      0.6124 1.9602
## hsGPA  0.2640 0.6429
## ACT   -0.0119 0.0307
```

- Resultado via fun√ß√£o `lm()`

```r
round( summary(reg)$coef, 4 ) # coeficientes
```

```
##             Estimate Std. Error t value Pr(>|t|)
## (Intercept)   1.2863     0.3408  3.7742   0.0002
## hsGPA         0.4535     0.0958  4.7327   0.0000
## ACT           0.0094     0.0108  0.8746   0.3833
```

```r
round( confint(reg), 4 ) # intervalos de confian√ßa
```

```
##               2.5 % 97.5 %
## (Intercept)  0.6124 1.9602
## hsGPA        0.2640 0.6429
## ACT         -0.0119 0.0307
```


</br>

## Transforma√ß√£o de Vari√°veis e Compara√ß√£o de Regress√µes

- [Se√ß√£o 4.4 de Heiss (2020)](http://www.urfie.net/read/index.html#page/137)
- Aqui, vamos utilizar um exemplo para mostrar como:
  - tranformar vari√°veis diretamente da fun√ß√£o `lm()`, e
  - informar os resultados de diversas regress√µes usando a fun√ß√£o `stargazer()` do pacote `stargazer`.


#### Exemplo 4.10 - A Rela√ß√£o Sal√°rio-Benef√≠cios de Professores
- Vamos usar a base de dados `meap93` do pacote `wooldridge` e queremos estimar o modelo

$$ \log{(\text{salary})} = \beta_0 + \beta_1. \left(\frac{\text{benefits}}{\text{salary}}\right) + \text{outros_fatores} + \varepsilon $$

- Primeiro, vamos carregar a base de dados e criar a vari√°vel benefits/salary (`b_s`):

```r
data(meap93, package="wooldridge") # carregando base de dados

# Definindo nova vari√°vel
meap93$b_s = meap93$benefits / meap93$salary
```

- Agora vamos estimar diversos modelos:
  - Modelo 1: apenas *benefits/salary* como regressor
  - Modelo 2: incluir as vari√°veis explicativas *log(enroll)* e *log(staff)*
  - Modelo 3: incluir as vari√°veis explicativas *droprate* e *droprate¬≤*

- Para fazer transforma√ß√µes dentro de `lm()`, √© necess√°rio usar a fun√ß√£o `I()`

```r
# Estimando os tr√™s modelos
model1 = lm(log(salary) ~ I(benefits/salary), meap93)
model2 = lm(log(salary) ~ I(benefits/salary) + log(enroll) + log(staff), meap93)
model3 = lm(log(salary) ~ I(benefits/salary) + log(enroll) +
              log(staff) + droprate + I(droprate^2), meap93)
round(summary(model3)$coef, 4)
```

```
##                    Estimate Std. Error t value Pr(>|t|)
## (Intercept)         10.8291     0.2514 43.0674   0.0000
## I(benefits/salary)  -0.5958     0.1655 -3.6008   0.0004
## log(enroll)          0.0877     0.0073 11.9509   0.0000
## log(staff)          -0.2173     0.0501 -4.3382   0.0000
## droprate            -0.0025     0.0021 -1.2014   0.2303
## I(droprate^2)        0.0000     0.0001  0.2851   0.7757
```


- Agora, vamos resumir os resultados em uma √∫nica tabela usando a fun√ß√£o `stargazer()` pacote `stargazer`
  - `type="text"` para retornar o resultado no pr√≥prio console (se omitir esse argumento, retorna o c√≥digo em LaTeX)
  - `keep.stat=c("n", "rsq")` para manter apenas os n¬∫ de observa√ß√µes e os {{<math>}}R$^2${{</math>}}


```r
# Resumindo em uma tabela
library(stargazer)
stargazer(list(model1, model2, model3), type="text", keep.stat=c("n", "rsq"))
```

```
## 
## ================================================
##                         Dependent variable:     
##                    -----------------------------
##                             log(salary)         
##                       (1)       (2)       (3)   
## ------------------------------------------------
## I(benefits/salary) -0.825*** -0.605*** -0.596***
##                     (0.200)   (0.165)   (0.165) 
##                                                 
## log(enroll)                  0.087***  0.088*** 
##                               (0.007)   (0.007) 
##                                                 
## log(staff)                   -0.222*** -0.217***
##                               (0.050)   (0.050) 
##                                                 
## droprate                                -0.002  
##                                         (0.002) 
##                                                 
## I(droprate2)                            0.00001 
##                                        (0.0001) 
##                                                 
## Constant           10.523*** 10.844*** 10.829***
##                     (0.042)   (0.252)   (0.251) 
##                                                 
## ------------------------------------------------
## Observations          408       408       408   
## R2                   0.040     0.353     0.358  
## ================================================
## Note:                *p<0.1; **p<0.05; ***p<0.01
```

- √â comum que os resultados econom√©tricos venham acompanhados de asteriscos (`*`), pois estes indicam o qu√£o significantes s√£o as estimativas.
- Quanto menor o n√≠vel de signific√¢ncia, mais asteriscos s√£o inseridos e estes facilitam a interpreta√ß√£o das estimativas estatisticamente diferentes de zero.


</br>

## Regressores Qualitativos

- Muitas vari√°veis de interesse s√£o qualitativas, ao inv√©s de quantitativas.
- Isso inclui vari√°veis como _sexo_, _cor/ra√ßa_, _status de trabalho_, _estado civil_, _escolha de marca_, etc.


### Vari√°veis Dummy

- [Se√ß√£o 7.1 de Heiss (2020)](http://www.urfie.net/read/index.html#page/161)
- Se um dado qualitativo est√° armazenado na base como uma vari√°vel qualitativa (ou seja, seus valores s√£o 0's ou 1's), ent√£o ele pode ser inserido imediatamente numa regress√£o linear.
- Se uma vari√°vel dummy for usada num modelo, seu coeficiente representa a diferen√ßa do intercepto entre os grupos (Wooldridge, 2006, Se√ß√£o 7.2)


##### Exemplo 7.5 - Equa√ß√£o do Log do Sal√°rio-Hora

- Vamos usar a base de dados `wage1` do pacote `wooldridge`
- Vamos estimar o modelo:

{{<math>}}\begin{align}
\text{wage} = &\beta_0 + \beta_1 \text{female} + \beta_2 \text{educ} + \beta_3 \text{exper} + \beta_4 \text{exper}^2 +\\
&\beta_5 \text{tenure} + \beta_6 \text{tenure}^2 + \varepsilon \tag{7.6} \end{align}{{</math>}}
em que:

- `wage`: sal√°rio m√©dio por hora
- `female`: dummy em que (1) mulher e (0) homem
- `educ`: anos de educa√ß√£o
- `exper`: anos de experi√™ncia (`expersq` = anos ao quadrado)
- `tenure`: anos de trabalho no empregador atual (`tenursq` = anos ao quadrado)


```r
# Carregando a base de dados necess√°ria
data(wage1, package="wooldridge")

# Estimando o modelo
reg_7.1 = lm(wage ~ female + educ + exper + expersq + tenure + tenursq, data=wage1)
round( summary(reg_7.1)$coef, 4 )
```

```
##             Estimate Std. Error t value Pr(>|t|)
## (Intercept)  -2.1097     0.7107 -2.9687   0.0031
## female       -1.7832     0.2572 -6.9327   0.0000
## educ          0.5263     0.0485 10.8412   0.0000
## exper         0.1878     0.0357  5.2557   0.0000
## expersq      -0.0038     0.0008 -4.9267   0.0000
## tenure        0.2117     0.0492  4.3050   0.0000
## tenursq      -0.0029     0.0017 -1.7473   0.0812
```

- Nota-se que as mulheres (`female = 1`) recebem em m√©dia $1,78/hora a menos, em rela√ß√£o aos homens (`female = 0`).
- Essa diferen√ßa √© estatisticamente significante (p-valor de `female` √© menor do que 5\%)



### Vari√°veis com m√∫ltiplas categorias

- [Se√ß√£o 7.3 de Heiss (2020)](http://www.urfie.net/read/index.html#page/164)
- Quando temos uma vari√°vel categ√≥rica com mais de 2 categorias, n√£o √© poss√≠vel simplesmente us√°-la na regress√£o como se fosse uma _dummy_.
- √â necess√°rio criar uma _dummy_ para cada categoria
- Quando for feita a estima√ß√£o do modelo, √© necess√°rio deixar uma destas categorias de fora para evitar problema de multicolinearidade perfeita.
  - Conhecendo todas as _dummies_ menos uma, d√° para saber o valor esta √∫ltima _dummy_
  - Se todas outras dummies forem iguais a 0, a √∫ltima dummy √© igual a 1
  - Se houver outra dummy igual a 1, ent√£o √∫ltima dummy √© igual a 0
- Al√©m disso, a categoria deixada de fora acaba sendo usada **refer√™ncia** quando s√£o estimados os par√¢metros.


##### Exemplo: Efeito do aumento do sal√°rio-m√≠nimo sobre o emprego (Card e Krueger, 1994)

- Em 1992, o estado de New Jersey (NJ) aumentou o sal√°rio m√≠nimo
- Para avaliar se o aumento do sal√°rio m√≠nimo teria impacto na quantidade de trabalhadores empregados, usou como compara√ß√£o o estado vizinho de Pennsylvania (PA), considerado parecido com NJ.
- Vamos estimar o seguinte modelo:

{{<math>}}$$`
\text{diff_fte} = \beta_0 + \beta_1 \text{nj} + \beta_2 \text{chain} + \beta_3 \text{hrsopen} + \varepsilon $${{</math>}}
em que:

- `diff_emptot`: diferen√ßa de n¬∫ de empregados entre fev/1992 e nov/1992
- `nj`: dummy em que (1) New Jersey - NJ, e (0) Pennsylvania - PA
- `chain`: rede de fast food: (1) Burger King (`bk`), (2) KFC (`kfc`), (3) Roy's (`roys`), e (4) Wendy's (`wendys`)
- `hrsopen`: horas de funcionamento por dia





```r
card1994 = read.csv("https://fhnishida.netlify.app/project/rec2301/card1994.csv")
head(card1994) # olhando as 6 primeiras linhas
```

```
##   sheet nj chain hrsopen diff_fte
## 1    46  0     1    16.5   -16.50
## 2    49  0     2    13.0    -2.25
## 3    56  0     4    12.0   -14.00
## 4    61  0     4    12.0    11.50
## 5   445  0     1    18.0   -41.50
## 6   451  0     1    24.0    13.00
```

- Note que a vari√°vel categ√≥rica `chain` possui n√∫meros ao inv√©s dos nomes das redes de fast food.
- Isto √© comum nas bases de dados, j√° que n√∫meros consomem menos espa√ßo de armazenamento.
- Caso voc√™ rode a estima√ß√£o com a vari√°vel `chain` desta maneira, o modelo considerar√° que √© uma vari√°vel cont√≠nua e prejudicando a sua an√°lise:


```r
lm(diff_fte ~ nj + hrsopen + chain, data=card1994)
```

```
## 
## Call:
## lm(formula = diff_fte ~ nj + hrsopen + chain, data = card1994)
## 
## Coefficients:
## (Intercept)           nj      hrsopen        chain  
##     0.40284      4.61869     -0.28458     -0.06462
```

- Note que a interpreta√ß√£o √© que a mudan√ßa de `bk` (1) para `kfc` (2) [ou  de `kfc` (2) para `roys` (3), ou de `roys` (3) para `wendys` (4)] diminuiu a varia√ß√£o do n¬∫ trabalhadores -- **o que n√£o faz sentido!**
- Portanto, precisamos criar as _dummies_ das vari√°veis categ√≥ricas:


```r
# Criando dummies para cada vari√°vel
card1994$bk = ifelse(card1994$chain==1, 1, 0)
card1994$kfc = ifelse(card1994$chain==2, 1, 0)
card1994$roys = ifelse(card1994$chain==3, 1, 0)
card1994$wendys = ifelse(card1994$chain==4, 1, 0)

# Visualizando as primeras linhas
head(card1994)
```

```
##   sheet nj chain hrsopen diff_fte bk kfc roys wendys
## 1    46  0     1    16.5   -16.50  1   0    0      0
## 2    49  0     2    13.0    -2.25  0   1    0      0
## 3    56  0     4    12.0   -14.00  0   0    0      1
## 4    61  0     4    12.0    11.50  0   0    0      1
## 5   445  0     1    18.0   -41.50  1   0    0      0
## 6   451  0     1    24.0    13.00  1   0    0      0
```

- Tamb√©m √© poss√≠vel criar _dummies_ mais facilmente usando o pacote `fastDummies`
- Observe que, usando apenas tr√™s colunas das redes de fast food, √© poss√≠vel saber o valor da 4¬™ coluna, pois cada observa√ß√£o/loja s√≥ pode ser de uma dessas 4 redes de fast food e, portanto, h√° apenas um `1` em cada linha.
- Portanto, caso coloquemos as 4 _dummies_ quando formos rodar a regress√£o, haver√° um problema de multicolinearidade perfeita:


```r
lm(diff_fte ~ nj + hrsopen + bk + kfc + roys + wendys, data=card1994)
```

```
## 
## Call:
## lm(formula = diff_fte ~ nj + hrsopen + bk + kfc + roys + wendys, 
##     data = card1994)
## 
## Coefficients:
## (Intercept)           nj      hrsopen           bk          kfc         roys  
##    2.097621     4.859363    -0.388792    -0.005512    -1.997213    -1.010903  
##      wendys  
##          NA
```

- Por padr√£o, o R j√° retira uma das categorias para servir como refer√™ncia.
- Aqui, a categoria `wendys` serve como refer√™ncia √†s estimativas das demais _dummies_
  - Em rela√ß√£o a `wendys`, o n¬∫ de empregados de:
    - `bk` teve uma varia√ß√£o de empregados muito parecida (apenas 0,005 menor)
    - `roys` teve uma diminui√ß√£o (menos 1 empregado)
    - `kfc` teve uma maior diminui√ß√£o (menos 2 empregados)
- Note que poder√≠amos usar como refer√™ncia outra rede de fast food, deixando sua _dummy_ de fora da regress√£o.
- Vamos deixar de fora a _dummy_ do `roys`:


```r
lm(diff_fte ~ nj + hrsopen + bk + kfc + wendys, data=card1994)
```

```
## 
## Call:
## lm(formula = diff_fte ~ nj + hrsopen + bk + kfc + wendys, data = card1994)
## 
## Coefficients:
## (Intercept)           nj      hrsopen           bk          kfc       wendys  
##      1.0867       4.8594      -0.3888       1.0054      -0.9863       1.0109
```

- Note agora que os par√¢metros est√£o em rela√ß√£o √† `roys``:
  - estimativa de `kfc` que tinha ficado -2, agora est√° "menos" negativo (-1)
  - estimativas de `bk` e de `wendys` possuem estimativas positivas (lembre-se que, em rela√ß√£o a `wendys`, a estimativa de `roys` foi negativo na regress√£o anterior)

</br>

- No R, na verdade, n√£o √© necess√°rio criar _dummies_ de uma vari√°vel categ√≥rica para rodar uma regress√£o, caso ela esteja como _texto_ ou como _factor_

- Criando vari√°vel da classe texto:

```r
card1994$chain_txt = as.character(card1994$chain) # criando vari√°vel texto
head(card1994$chain_txt) # Visualizado os primeiros valores
```

```
## [1] "1" "2" "4" "4" "1" "1"
```

```r
# Estimando do modelo
lm(diff_fte ~ nj + hrsopen + chain_txt, data=card1994)
```

```
## 
## Call:
## lm(formula = diff_fte ~ nj + hrsopen + chain_txt, data = card1994)
## 
## Coefficients:
## (Intercept)           nj      hrsopen   chain_txt2   chain_txt3   chain_txt4  
##    2.092109     4.859363    -0.388792    -1.991701    -1.005391     0.005512
```

- Observe que a fun√ß√£o `lm()` retira a categoria que aparece primeiro no vetor de texto (`"1"`)
- Usando como vari√°vel texto, n√£o √© poss√≠vel selecionar facilmente qual categoria vai ser retirada da regress√£o
- Para isto, podemos usar a classe de objeto `factor`:


```r
card1994$chain_fct = factor(card1994$chain) # criando vari√°vel factor
levels(card1994$chain_fct) # verificando os n√≠veis (categorias) da vari√°vel factor
```

```
## [1] "1" "2" "3" "4"
```

```r
# Estimando do modelo
lm(diff_fte ~ nj + hrsopen + chain_fct, data=card1994)
```

```
## 
## Call:
## lm(formula = diff_fte ~ nj + hrsopen + chain_fct, data = card1994)
## 
## Coefficients:
## (Intercept)           nj      hrsopen   chain_fct2   chain_fct3   chain_fct4  
##    2.092109     4.859363    -0.388792    -1.991701    -1.005391     0.005512
```

- Note que a fun√ß√£o `lm()` retira o primeiro n√≠vel da regress√£o (n√£o necessariamente o que aparece primeiro na base de dados)
- Podemos trocar a refer√™ncia usando a fun√ß√£o `relevel()` em uma vari√°vel _factor_

```r
card1994$chain_fct = relevel(card1994$chain_fct, ref="3") # refer√™ncia roys
levels(card1994$chain_fct) # verificando os n√≠veis da vari√°vel factor
```

```
## [1] "3" "1" "2" "4"
```

```r
# Estimando do modelo
lm(diff_fte ~ nj + hrsopen + chain_fct, data=card1994)
```

```
## 
## Call:
## lm(formula = diff_fte ~ nj + hrsopen + chain_fct, data = card1994)
## 
## Coefficients:
## (Intercept)           nj      hrsopen   chain_fct1   chain_fct2   chain_fct4  
##      1.0867       4.8594      -0.3888       1.0054      -0.9863       1.0109
```

- Observe que o primeiro n√≠vel foi alterado para `"3"` e, portanto, essa categoria foi retirada na regress√£o



### Transformando vari√°veis cont√≠nuas em categorias
- [Se√ß√£o 7.4 de Heiss (2020)](http://www.urfie.net/read/index.html#page/166) 
- Usando a fun√ß√£o `cut()`, podemos "dividir" um vetor de n√∫meros em intervalos, a partir de pontos de corte


```r
# Definindo pontos de corte
cutpts = c(0, 3, 6, 10)

# Classificando o vetor 1:10 a partir dos pontos de corte
cut(1:10, cutpts)
```

```
##  [1] (0,3]  (0,3]  (0,3]  (3,6]  (3,6]  (3,6]  (6,10] (6,10] (6,10] (6,10]
## Levels: (0,3] (3,6] (6,10]
```


##### Exemplo 7.8 - Efeitos da Classifica√ß√£o das Faculdade de Direito sobre Sal√°rios Iniciais

- Queremos verificar o quanto as universidades top 10 (`top10`), e as ranqueadas entre 11 e 25 (`r11_25`), entre 26 e 40 (`r26_40`), entre 41 e 60 (`r41_60`), e entre 61 e 100 (`r61_100`), impactam o log do sal√°rio (`log(salary)`) em rela√ß√£o √†s demais universidades (`r101_175`).
- Utilizaremos como vari√°veis de controle: `LSAT`, `GPA`, `llibvol` e `lcost`


```r
data(lawsch85, package="wooldridge") # carregando base de dados necess√°ria

# Definindo pontos de corte
cutpts = c(0, 10, 25, 40, 60, 100, 175)

# Criando vari√°vel com a classifica√ß√£o
lawsch85$rankcat = cut(lawsch85$rank, cutpts)

# Visualizando os 6 primeiros valores de rankcat
head(lawsch85$rankcat)
```

```
## [1] (100,175] (100,175] (25,40]   (40,60]   (60,100]  (60,100] 
## Levels: (0,10] (10,25] (25,40] (40,60] (60,100] (100,175]
```

```r
# Escolhendo a categoria de refer√™ncia (acima de 100 at√© 175)
lawsch85$rankcat = relevel(lawsch85$rankcat, '(100,175]')

# Estimando o modelo
res = lm(log(salary) ~ rankcat + LSAT + GPA + llibvol + lcost, data=lawsch85)
round( summary(res)$coef, 5 )
```

```
##                 Estimate Std. Error  t value Pr(>|t|)
## (Intercept)      9.16530    0.41142 22.27699  0.00000
## rankcat(0,10]    0.69957    0.05349 13.07797  0.00000
## rankcat(10,25]   0.59354    0.03944 15.04926  0.00000
## rankcat(25,40]   0.37508    0.03408 11.00536  0.00000
## rankcat(40,60]   0.26282    0.02796  9.39913  0.00000
## rankcat(60,100]  0.13159    0.02104  6.25396  0.00000
## LSAT             0.00569    0.00306  1.85793  0.06551
## GPA              0.01373    0.07419  0.18500  0.85353
## llibvol          0.03636    0.02602  1.39765  0.16467
## lcost            0.00084    0.02514  0.03347  0.97336
```

- Note que, em rela√ß√£o √†s universidades em piores coloca√ß√µes (`(100,175]`), as melhores ranqueadas prov√™em sal√°rios de 13,16\% a 69,96\% superiores


### Intera√ß√µes Envolvendo Vari√°veis Dummy

#### Intera√ß√µes entre vari√°veis dummy
- [Subse√ß√£o 6.1.6 de Heiss (2020)](http://www.urfie.net/read/index.html#page/154)
- Se√ß√£o 7. de Wooldridge (2006)
- Adicionando um termo de intera√ß√£o entre duas _dummies_, √© poss√≠vel obter estimativas distintas de uma _dummy_ (mudan√ßa no **intercepto**) para cada um das 2 categorias da outra _dummy_ (0 e 1).


##### (Continua√ß√£o) Exemplo 7.5 - Equa√ß√£o do Log do Sal√°rio-Hora

- Retornemos √† base de dados `wage1` do pacote `wooldridge`
- Agora, vamos incluir a vari√°vel _dummy_ `married`

- O modelo a ser estimado √©:

{{<math>}}\begin{align}
\log(\text{wage}) = &\beta_0 + \beta_1 \text{female} + \beta_2 \text{married} + \beta_3 \text{educ} +\\
&\beta_4 \text{exper} + \beta_5 \text{exper}^2 + \beta_6 \text{tenure} + \beta_7 \text{tenure}^2 + \varepsilon \end{align}{{</math>}}
em que:

- `wage`: sal√°rio m√©dio por hora
- `female`: dummy em que (1) mulher e (0) homem
- `married`: dummy em que (1) casado e (0) solteiro
- `educ`: anos de educa√ß√£o
- `exper`: anos de experi√™ncia (`expersq` = anos ao quadrado)
- `tenure`: anos de trabalho no empregador atual (`tenursq` = anos ao quadrado)



```r
# Carregando a base de dados necess√°ria
data(wage1, package="wooldridge")

# Estimando o modelo
reg_7.11 = lm(lwage ~ female + married + educ + exper + expersq + tenure + tenursq, data=wage1)
round( summary(reg_7.11)$coef, 4 )
```

```
##             Estimate Std. Error t value Pr(>|t|)
## (Intercept)   0.4178     0.0989  4.2257   0.0000
## female       -0.2902     0.0361 -8.0356   0.0000
## married       0.0529     0.0408  1.2985   0.1947
## educ          0.0792     0.0068 11.6399   0.0000
## exper         0.0270     0.0053  5.0609   0.0000
## expersq      -0.0005     0.0001 -4.8135   0.0000
## tenure        0.0313     0.0068  4.5700   0.0000
## tenursq      -0.0006     0.0002 -2.4475   0.0147
```

- Por essa regress√£o, nota-se que casar-se tem efeito estatisticamente n√£o significante e positivo de 5,29\% sobre o sal√°rio.
- O fato deste efeito n√£o ser significante pode estar relacionado aos efeitos distintos dos casamentos sobre os homens, que t√™m seus sal√°rios elevados, e as mulheres, que t√™m seus sal√°rios diminu√≠dos.
- Para avaliar diferentes efeitos distintos do casamento considerando o sexo do indiv√≠duo, podemos interagir (multiplicar) as vari√°veis `married` e `female` usando:
  - `lwage ~ female + married + married:female` (o `:` cria apenas a intera√ß√£o), ou
  - `lwage ~ female * married` (a "multiplica√ß√£o" cria as dummies e a intera√ß√£o)

- O modelo a ser estimado agora √©:
{{<math>}}\begin{align}
\log(\text{wage}) = &\beta_0 + \beta_1 \text{female} + \beta_2 \text{married} + \delta_2 \text{female*married} + \beta_3 \text{educ} + \\
&\beta_4 \text{exper} + \beta_5 \text{exper}^2 + \beta_6 \text{tenure} + \beta_7 \text{tenure}^2 + \varepsilon \end{align}{{</math>}}


```r
# Estimando o modelo - forma (a)
reg_7.14a = lm(lwage ~ female + married + female:married + educ + exper + expersq + tenure + tenursq,
               data=wage1)
round( summary(reg_7.14a)$coef, 4 )
```

```
##                Estimate Std. Error t value Pr(>|t|)
## (Intercept)      0.3214     0.1000  3.2135   0.0014
## female          -0.1104     0.0557 -1.9797   0.0483
## married          0.2127     0.0554  3.8419   0.0001
## educ             0.0789     0.0067 11.7873   0.0000
## exper            0.0268     0.0052  5.1118   0.0000
## expersq         -0.0005     0.0001 -4.8471   0.0000
## tenure           0.0291     0.0068  4.3016   0.0000
## tenursq         -0.0005     0.0002 -2.3056   0.0215
## female:married  -0.3006     0.0718 -4.1885   0.0000
```

```r
# Estimando o modelo - forma (b)
reg_7.14b = lm(lwage ~ female * married + educ + exper + expersq + tenure + tenursq,
               data=wage1)
round( summary(reg_7.14b)$coef, 4 )
```

```
##                Estimate Std. Error t value Pr(>|t|)
## (Intercept)      0.3214     0.1000  3.2135   0.0014
## female          -0.1104     0.0557 -1.9797   0.0483
## married          0.2127     0.0554  3.8419   0.0001
## educ             0.0789     0.0067 11.7873   0.0000
## exper            0.0268     0.0052  5.1118   0.0000
## expersq         -0.0005     0.0001 -4.8471   0.0000
## tenure           0.0291     0.0068  4.3016   0.0000
## tenursq         -0.0005     0.0002 -2.3056   0.0215
## female:married  -0.3006     0.0718 -4.1885   0.0000
```

- Observe que, agora, o par√¢metro de casado refere-se apenas aos homens (`married`) √© positivo e significante de 21,27\%.
- J√°, sobre as mulheres, o casamento tem o efeito de {{<math>}}$\beta_2 + \delta_2${{</math>}}, ou seja, √© igual a -8,79\% (= 0,2127 - 0,3006)
- Uma hip√≥tese importante √© a {{<math>}}H$_0:\ \delta_2 = 0${{</math>}} para verificar se o retorno por mudan√ßa do estado civil (**intercepto**) √© diferente entre mulheres e homens.
- No output da regress√£o, podemos ver que o par√¢metros da intera√ß√£o (`female:married`) √© significante (p-valor bem baixo), logo, o efeito do casamento sobre a mulher √© estatisticamente diferente do efeito sobre o homem.


</br>

#### Considerando inclina√ß√µes diferentes
- Se√ß√£o 7.4 de Wooldridge (2006)
- [Se√ß√£o 7.5 de Heiss (2020)](http://www.urfie.net/read/index.html#page/168)
- Adicionando um termo de intera√ß√£o entre uma vari√°vel cont√≠nua e uma _dummy_, √© poss√≠vel obter estimativas distintas de da vari√°vel num√©rica (mudan√ßa na **inclina√ß√£o**) para cada um das 2 categorias da _dummy_ (0 e 1).



##### Exemplo 7.10 - Equa√ß√£o do Log do Sal√°rio-Hora

- Retornemos √† base de dados `wage1` do pacote `wooldridge`
- Suspeita-se que as mulheres, al√©m de terem um intercepto distinto em rela√ß√£o aos homens, tamb√©m tem menores retornos de sal√°rio para cada ano de educa√ß√£o a mais.
- Ent√£o, incluiremos no modelo a intera√ß√£o entre a dummy `female` e os anos de educa√ß√£o (`educ`):

{{<math>}}\begin{align}
\log(\text{wage}) = &\beta_0 + \beta_1 \text{female} + \beta_2 \text{educ} + \delta_2 \text{female*educ} \\
&\beta_3 \text{exper} + \beta_4 \text{exper}^2 + \beta_5 \text{tenure} + \beta_6 \text{tenure}^2 + \varepsilon \end{align}{{</math>}}
em que:

- `wage`: sal√°rio m√©dio por hora
- `female`: dummy em que (1) mulher e (0) homem
- `educ`: anos de educa√ß√£o
- `female*educ`: intera√ß√£o entre a dummy `female` e anos de educa√ß√£o (`educ`)
- `exper`: anos de experi√™ncia (`expersq` = anos ao quadrado)
- `tenure`: anos de trabalho no empregador atual (`tenursq` = anos ao quadrado)


```r
# Carregando a base de dados necess√°ria
data(wage1, package="wooldridge")

# Estimando o modelo
reg_7.17 = lm(lwage ~ female + educ + female:educ + exper + expersq + tenure + tenursq,
              data=wage1)
round( summary(reg_7.17)$coef, 4 )
```

```
##             Estimate Std. Error t value Pr(>|t|)
## (Intercept)   0.3888     0.1187  3.2759   0.0011
## female       -0.2268     0.1675 -1.3536   0.1764
## educ          0.0824     0.0085  9.7249   0.0000
## exper         0.0293     0.0050  5.8860   0.0000
## expersq      -0.0006     0.0001 -5.3978   0.0000
## tenure        0.0319     0.0069  4.6470   0.0000
## tenursq      -0.0006     0.0002 -2.5089   0.0124
## female:educ  -0.0056     0.0131 -0.4260   0.6703
```

- Uma hip√≥tese importante √© a {{<math>}}H$_0:\ \delta_2 = 0${{</math>}} para verificar se o retorno a cada ano de educa√ß√£o (**inclina√ß√£o**) √© diferente entre mulheres e homens.
- Pela estima√ß√£o, nota-se que o incremento no sal√°rio das mulheres para cada ano a mais de educa√ß√£o √© 0,56\% menor em rela√ß√£o aos homens:
  - Homens aumentam 8,24\% (`educ`) o sal√°rio para cada ano de educa√ß√£o
  - Mulheres aumentam 7,58\% (= 0,0824 - 0,0056) o sal√°rio para cada ano de educa√ß√£o
- No entanto, essa diferen√ßa √© estatisticamente n√£o-significante a 5\% de signific√¢ncia.

<img src="../example_interaction.png" alt="">



{{< cta cta_text="üëâ Proceed to Hypothesis Testing" cta_link="../sec9" >}}
